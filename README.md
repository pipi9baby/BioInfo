# BioInfo
# 作業一
# 開發環境：
Python
# IDE：
VS code
# 使用到的套件：
numpy(做矩陣運算)、tkinter(圖形化介面)、pickle(保存train好的機器學習模型)、gensim(計算word to vector)、pattern(做字詞歸一)、sklearn(機器學習)

# 需求：
輸入檔案路徑（XML或JSON）＆關鍵字，用圖形化介面的方式顯示檔案內容和查找到的關鍵字。另外需計算字元數、單字數、句數，句數需要使用自動化的方式分析，而不是Rule base。
XML：顯示論文的標題、概要及作者
JSON：顯示twitter的推文、推文者及發布推文的時間

# 方法：
XML、JSON讀檔：使用正則表示式，XML只截取標題、作者、概要，JSON只截取推文內容。
字元數、單字數：使用正則表示式的方法來做計算。
關鍵字搜索：使用pattern裡存好的各種單字來做歸一，歸一後的結果相等就會用不同方式顯示那個關鍵字。
斷句分析：使用我自己建好的training data(共35筆，其中13筆資料不是句子)，用SVM來建模型。輸入test data的時候則是找文章最近的一個「.」、「！」、「？」，擷取出這段話來詢問機器學習模型該筆資料是否為句子，是的話句數計算會加一，否的話則繼續往後擷取一段文字直至被模型判斷為一段句子為止。輸入進模型的數據格式則是將每個字取100維度的word to vector，並將一句話中的每個字取平均，如果遇到無法轉換成vector的字則上一個通用的unknow標籤。
測試資料來源：XML檔案從PubMed中直接下載。JSON的檔案使用tweet這項API來下載，下載前須向twitter申請，並說明使用twitter資料做何種用途才可下載。
